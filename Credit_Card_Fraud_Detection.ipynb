{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/EDA_extensive_library/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPUL4qyNXwtk"
      },
      "source": [
        "# **Credit-Card Fraud Detection**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve99BK235qci"
      },
      "source": [
        "1. Introduction\n",
        "2. Preliminaries - load packages\n",
        "3. Import dataset\n",
        "4. Exploratory data analysis\n",
        "5. Predictive modeling\n",
        "6. Results and conclusion\n",
        "7. References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7On3UP4d25Pv"
      },
      "source": [
        "## **1. Introduction**\n",
        "\n",
        "\n",
        "- Credit card fraud is when someone uses our credit card or credit account to make a purchase we didn't authorize.\n",
        "\n",
        "- Fraudsters steal ₹615.39 crore in more than 1.17 lakh cases of credit and debit card frauds over 10 years (April 2009 to September 2019), Reserve Bank of India (RBI) data revealed.\n",
        "\n",
        "- So, in this project, we attempt to detect credit-card frauds.\n",
        "\n",
        "- So, let's get started. First, we take a look at the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey92SsoF2aOu"
      },
      "source": [
        "- The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "- It contains only numerical input variables which are the result of a PCA transformation.\n",
        "\n",
        "- Due to confidentiality issues, the are not provided the original features and more background information about the data.\n",
        "\n",
        "  - Features V1, V2, ... V28 are the principal components obtained with PCA;\n",
        "  - The only features which have not been transformed with PCA are Time and Amount. Feature Time contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature Amount is the transaction Amount, this feature can be used for example-dependant cost-senstive learning.\n",
        "  - Feature Class is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGZpGgvS5Tkv"
      },
      "source": [
        "## **2. Preliminaries - load packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ioh8rknaXm2n",
        "outputId": "6459f147-09fe-464b-9688-08a9d82071de"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixhW2b6r7hek",
        "outputId": "686a977c-e96a-45c5-e61a-46a2fde91ef4"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dbyt7tcijGt"
      },
      "source": [
        "import gc\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn import svm\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Z0UJrXi5IV"
      },
      "source": [
        "pd.set_option('display.max_columns', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw9VKn8HjHzD"
      },
      "source": [
        "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
        "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
        "NO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKTMKdNHjLTf"
      },
      "source": [
        "#TRAIN/VALIDATION/TEST SPLIT\n",
        "#VALIDATION\n",
        "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
        "TEST_SIZE = 0.20 # test size using_train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8R3rHPjjTVh"
      },
      "source": [
        "#CROSS-VALIDATION\n",
        "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geO8rPlZkFdr"
      },
      "source": [
        "RANDOM_STATE = 2024\n",
        "\n",
        "MAX_ROUNDS = 1000 #lgb iterations\n",
        "EARLY_STOP = 50 #lgb early stop\n",
        "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
        "VERBOSE_EVAL = 50 #Print out metric result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPiz75iv6r1t"
      },
      "source": [
        "## **3. Import dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqEAY9fjkGxC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lCLv9jrxu8P"
      },
      "source": [
        "path = '/content/drive/MyDrive/CreditCard_Fraud_Detection/creditcard.csv'\n",
        "\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___pXNbk6yl8"
      },
      "source": [
        "## **4. Exploratory data analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFqKbp7CmYdp"
      },
      "source": [
        "Let's first check the shape of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tPAt-uB70b4"
      },
      "source": [
        "print(\"Credit Card Fraud Detection data -  rows:\", df.shape[0],\" columns:\", df.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIEHTX6VmfUK"
      },
      "source": [
        "We can see that the dataset contains 284807 rows and 31 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGAGABnOmuP0"
      },
      "source": [
        "Now, we will take a look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCV3eJq5x1qy"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj-aayzFm752"
      },
      "source": [
        "Now, let's take a more closer look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY9dDh0qnAFk"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMK_EZGOnMS-"
      },
      "source": [
        "- We can see that all the 31 features are of numerical type - 30 are of float data type and 1 is of integer data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA6e7Bq1oGw2"
      },
      "source": [
        "- Now, let's take a more indepth look of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jx0k0YXnB1J"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VF2pCWKo6bv"
      },
      "source": [
        "- If we look at the time feature, we can confirm that the data contains 284,807 transactions, during 2 consecutive days (or 172792 seconds)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-53fAP9pggP"
      },
      "source": [
        "#### **Check for missing values**\n",
        "\n",
        "- Now, let's check for missing values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhXBrNK2ptXl"
      },
      "source": [
        "df.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olv2LRhPp4re"
      },
      "source": [
        "- We can see that the dataset does not contain any missing values. We can confirm this further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MiX4YHqqD3P"
      },
      "source": [
        "df.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16gPOaT_qK4J"
      },
      "source": [
        "- We can see that there are no missing values in the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn5fMUd5gtuq"
      },
      "source": [
        "#### **Visualize distribution of time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDEvnWSqtb_8"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Distribution of Time')\n",
        "sns.histplot(df.Time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOGTEeZWjowI"
      },
      "source": [
        "#### **Visualize fraudulent Vs normal transactions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmtGVQqhhGu4"
      },
      "source": [
        "#fraud vs. normal transactions\n",
        "counts = df.Class.value_counts()\n",
        "normal = counts[0]\n",
        "fraudulent = counts[1]\n",
        "perc_normal = (normal/(normal+fraudulent))*100\n",
        "perc_fraudulent = (fraudulent/(normal+fraudulent))*100\n",
        "print('There were {} non-fraudulent transactions ({:.3f}%) and {} fraudulent transactions ({:.3f}%).'.format(normal, perc_normal, fraudulent, perc_fraudulent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzthvqVvtBGH"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=counts.index, y=counts)\n",
        "plt.title('Count of Fraudulent vs. Non-Fraudulent Transactions')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe7aCOPFj91R"
      },
      "source": [
        "#### **Features Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx8buOFbqUcA"
      },
      "source": [
        "plt.figure(figsize = (12,10))\n",
        "plt.title('Credit card transactions features correlation plot')\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,linewidths=.1,cmap=\"Reds\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7orCCTXlIWT"
      },
      "source": [
        "- As expected, there is no notable correlation between features **V1-V28**.\n",
        "- There are certain correlations between some of these features and **Time** (inverse correlation with **V3**) and **Amount** (direct correlation with **V7** and **V20**, inverse correlation with **V1** and **V5**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVV-pEdUlpVq"
      },
      "source": [
        "- Let's plot the correlated and inverse correlated values on the same graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPbC5QhIltlq"
      },
      "source": [
        "- Let's start with the direct correlated values: {**V20;Amount**} and {**V7;Amount**}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZDO84kls7D"
      },
      "source": [
        "s = sns.lmplot(x = 'V20', y = 'Amount',data = df, hue = 'Class', fit_reg = True, scatter_kws = {'s':2})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mWkU62KqJVj"
      },
      "source": [
        "s = sns.lmplot(x = 'V7', y = 'Amount',data = df, hue = 'Class', fit_reg = True, scatter_kws = {'s':2})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XS9UUnDol9t"
      },
      "source": [
        "We can confirm that the two couples of features are correlated (the regression lines for **Class = 0** have a positive slope, whilst the regression line for **Class = 1** have a smaller positive slope)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WARmcPTpABX"
      },
      "source": [
        "Let's now plot now the inverse correlated values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K1pP-i1pwFY"
      },
      "source": [
        "s = sns.lmplot(x = 'V2', y = 'Amount', data = df, hue = 'Class', fit_reg = True, scatter_kws = {'s':2})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD0wM8ekpSv3"
      },
      "source": [
        "s = sns.lmplot(x = 'V5', y = 'Amount', data = df, hue = 'Class', fit_reg = True, scatter_kws = {'s':2})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eKXcqarOsh"
      },
      "source": [
        "- We can confirm that the two couples of features are inverse correlated (the regression lines for **Class = 0** have a negative slope while the regression lines for **Class = 1** have a very small negative slope)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA6adWBarcX6"
      },
      "source": [
        "#### **Features density plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMyYP30oOfT"
      },
      "source": [
        "var = df.columns.values\n",
        "\n",
        "i = 0\n",
        "t0 = df.loc[df['Class'] == 0]\n",
        "t1 = df.loc[df['Class'] == 1]\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(8,4,figsize=(16,28))\n",
        "\n",
        "for feature in var:\n",
        "    i += 1\n",
        "    plt.subplot(8,4,i)\n",
        "    sns.kdeplot(t0[feature], label = \"Class = 0\")\n",
        "    sns.kdeplot(t1[feature], label = \"Class = 1\")\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis = 'both', which = 'major', labelsize = 12)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKyGoeYZte9x"
      },
      "source": [
        "- For some of the features we can observe a good selectivity in terms of distribution for the two values of **Class: V4, V11** have clearly separated distributions for **Class** values 0 and 1, **V12**, **V14**, **V18** are partially separated, **V1**, **V2**, **V3**, **V10** have a quite distinct profile, whilst **V25**, **V26**, **V28** have similar profiles for the two values of Class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjYrCE7luCwR"
      },
      "source": [
        "- In general, with just few exceptions (**Time** and **Amount**), the features distribution for legitimate transactions (values of **Class = 0**) is centered around 0, sometime with a long queue at one of the extremities. In the same time, the fraudulent transactions (values of **Class = 1**) have a skewed (asymmetric) distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Vgb3Nrug_B"
      },
      "source": [
        "## **5. Predictive Modelling**\n",
        "\n",
        "- Now, we will move on to predictive modelling. We will define predictor and target values and evaluate various model performance on them. So, let's do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1DGGh8_3P4E"
      },
      "source": [
        "#### **Define predictors and target values**\n",
        "\n",
        "- Now, let's define the predictor features and target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVKh5O6w3mfr"
      },
      "source": [
        "target = 'Class'\n",
        "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
        "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
        "       'Amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEeDcs6z36Qx"
      },
      "source": [
        "#### **Split data in train, test and validation set**\n",
        "\n",
        "- Now, let's define train, validation and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vx7wDqd4SCg"
      },
      "source": [
        "- First, we will split the dataset into train and test set as follows-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dN0LLFW3vNy"
      },
      "source": [
        "train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trhe9DVz4ek3"
      },
      "source": [
        "- Now, we will split the training set into train and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhokpcjnyrJx"
      },
      "source": [
        "train_df, valid_df = train_test_split(train_df, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twgN12p542Zr"
      },
      "source": [
        "### **Random Forest Classifier**\n",
        "\n",
        "- Now, we will first start with the Random Forest Classifier  model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7PT-D2R5R8r"
      },
      "source": [
        "- Define model parameters - Let's set the parameters for the model. Let's run a model using the training set for training. Then, we will use the validation set for validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCPOFDR55i4n"
      },
      "source": [
        "- We will use as validation criterion **GINI**. Its formula is **GINI = 2 * (AUC) - 1**, where **AUC** is the **Receiver Operating Characteristic - Area Under Curve (ROC-AUC)**. Number of estimators is set to **100** and number of parallel jobs is set to **4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHeciChm5fDX"
      },
      "source": [
        "- We start by initializing the **RandomForestClassifier**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_hsvBvXx4mb"
      },
      "source": [
        "clf = RandomForestClassifier(n_jobs=NO_JOBS,\n",
        "                             random_state=RANDOM_STATE,\n",
        "                             criterion=RFC_METRIC,\n",
        "                             n_estimators=NUM_ESTIMATORS,\n",
        "                             verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTwaWWgD6d2L"
      },
      "source": [
        "- Now, let's train the Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jZFo6mo6jT1"
      },
      "source": [
        "clf.fit(train_df[predictors], train_df[target].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALTqotY47Y3j"
      },
      "source": [
        "- Now, let's predict the target values for the valid_df data, using predict function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_Jg7Ae6mus"
      },
      "source": [
        "preds = clf.predict(valid_df[predictors])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-iURsW77nHG"
      },
      "source": [
        "#### **Features importance**\n",
        "\n",
        "- Now, let's visualize the features importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NcajJVi7hYO"
      },
      "source": [
        "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "plt.figure(figsize = (7,4))\n",
        "plt.title('Features importance',fontsize=14)\n",
        "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGYB2ZW8IIf"
      },
      "source": [
        "- The most important features are **V17**, **V12**, **V14**, **V16**, **V11**, **V10**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeqpPEq98ksW"
      },
      "source": [
        "#### **Confusion matrix**\n",
        "\n",
        "- Now, let's plot the confusion matrix for the results we obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RixZymcv6VVh"
      },
      "source": [
        "cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
        "sns.heatmap(cm,\n",
        "            xticklabels=['Not Fraud', 'Fraud'],\n",
        "            yticklabels=['Not Fraud', 'Fraud'],\n",
        "            annot=True,ax=ax1,\n",
        "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayb7V7Dbvt3v"
      },
      "source": [
        " #### **Type I error** and **Type II error**\n",
        "\n",
        "- Now, confussion matrix is not a very good tool to represent the results in the case of highly unbalanced data, like in this case. We will actually need a different metric that accounts in the same time for the selectivity and specificity of the method we are using, so that we minimize in the same time both Type I errors and Type II errors.\n",
        "\n",
        "- **Null Hypothesis (H0)** - The transaction is not a fraud.\n",
        "- **Alternative Hypothesis (H1)** - The transaction is a fraud.\n",
        "\n",
        "- **Type I error** - We reject the null hypothesis when the null hypothesis is actually true.\n",
        "- **Type II error** - We fail to reject the null hypothesis when the the alternative hypothesis is true.\n",
        "\n",
        "- **Cost of Type I error** - We erroneously presume that the the transaction is a fraud, and a true transaction is rejected.\n",
        "- **Cost of Type II error** - We erroneously presume that the transaction is not a fraud and a ffraudulent transaction is accepted.\n",
        "\n",
        "\n",
        "- So, **Type II error** is more dangerous than a **Type I error**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH64VNHLw6Az"
      },
      "source": [
        "#### **ROC-AUC Score**\n",
        "\n",
        "- Now, let's calculate the ROC-AUC Score of the Random Forest Classifier model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcVrbuH_xTDp"
      },
      "source": [
        "roc_auc_score(valid_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1RaEAvCxjkF"
      },
      "source": [
        "- So, the **ROC-AUC score** obtained with Random Forrest Classifier is 0.85."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrhOKtdxqk9"
      },
      "source": [
        "### **AdaBoost Classifier**\n",
        "\n",
        "- **AdaBoost Classifier** stands for Adaptive Boosting Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01YK1UPwyQYT"
      },
      "source": [
        "#### **Initialize the model**\n",
        "\n",
        "- Let's set the parameters for the model and initialize the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8J1T8xmuSyd"
      },
      "source": [
        "clf = AdaBoostClassifier(random_state=RANDOM_STATE,\n",
        "                         algorithm='SAMME.R',\n",
        "                         learning_rate=0.8,\n",
        "                             n_estimators=NUM_ESTIMATORS)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nut4d6SQy0wU"
      },
      "source": [
        "#### **Fit the model**\n",
        "\n",
        "- Now, let's fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BzRLW39y95N"
      },
      "source": [
        "clf.fit(train_df[predictors], train_df[target].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh1_BDl81QT2"
      },
      "source": [
        "#### **Predict the target values**\n",
        "\n",
        "- Let's now predict the target values for the valid_df data, using predict function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F691usFG1WYR"
      },
      "source": [
        "preds = clf.predict(valid_df[predictors])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkpQuUi1gKr"
      },
      "source": [
        "#### **Features importance**\n",
        "\n",
        "- Let's see the features importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jivMlQF_1asg"
      },
      "source": [
        "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title('Features importance',fontsize=14)\n",
        "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpLoVgcO15Sh"
      },
      "source": [
        "#### **Confusion matrix**\n",
        "\n",
        "- Let's visualize the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntYyogtnzCqL"
      },
      "source": [
        "cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
        "sns.heatmap(cm,\n",
        "            xticklabels=['Not Fraud', 'Fraud'],\n",
        "            yticklabels=['Not Fraud', 'Fraud'],\n",
        "            annot=True,ax=ax1,\n",
        "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-qhTmT64JE"
      },
      "source": [
        "#### **ROC-AUC Score**\n",
        "\n",
        "Let's calculate also the ROC-AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYZbtCtU7AoL"
      },
      "source": [
        "roc_auc_score(valid_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGbYWxqb-Um7"
      },
      "source": [
        "The ROC-AUC score obtained with AdaBoostClassifier is 0.83."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMOYKflN_LEv"
      },
      "source": [
        "### **CatBoost Classifier**\n",
        "\n",
        "- **CatBoost Classifier** is a gradient boosting for decision trees algorithm with support for handling categorical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp3VXIBl_toJ"
      },
      "source": [
        "#### **Initialize the model**\n",
        "\n",
        "- Let's set the parameters for the model and initialize the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luDH3tqQA_9a"
      },
      "source": [
        "clf = CatBoostClassifier(iterations=500,\n",
        "                             learning_rate=0.02,\n",
        "                             depth=12,\n",
        "                             eval_metric='AUC',\n",
        "                             random_seed = RANDOM_STATE,\n",
        "                             bagging_temperature = 0.2,\n",
        "                             od_type='Iter',\n",
        "                             metric_period = VERBOSE_EVAL,\n",
        "                             od_wait=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QefGQoyBBIJw"
      },
      "source": [
        "clf.fit(train_df[predictors], train_df[target].values,verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_22y0lLCF18"
      },
      "source": [
        "#### **Predict the target values**\n",
        "\n",
        "- Let's now predict the target values for the **val_df** data, using predict function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr7luDKeCM90"
      },
      "source": [
        "preds = clf.predict(valid_df[predictors])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H29RlTcnCiFm"
      },
      "source": [
        "#### **Features importance**\n",
        "\n",
        "- Let's see also the features importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSQKh6SrCmWg"
      },
      "source": [
        "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title('Features importance',fontsize=14)\n",
        "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5LenS3fDMi0"
      },
      "source": [
        "#### **Confusion matrix**\n",
        "\n",
        "- Let's visualize the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zmOQGaCsuV"
      },
      "source": [
        "cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
        "sns.heatmap(cm,\n",
        "            xticklabels=['Not Fraud', 'Fraud'],\n",
        "            yticklabels=['Not Fraud', 'Fraud'],\n",
        "            annot=True,ax=ax1,\n",
        "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCG81a5ADm6H"
      },
      "source": [
        "#### **ROC-AUC Score**\n",
        "\n",
        "- Now, let's calculate also the ROC-AUC Score.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBoZI_HmDxKB"
      },
      "source": [
        "roc_auc_score(valid_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxbxuwMZD4qF"
      },
      "source": [
        "- The ROC-AUC score obtained with CatBoostClassifier is 0.86.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LlYPX4kEeP8"
      },
      "source": [
        "### **XGBoost Classifier**\n",
        "\n",
        "\n",
        "- **XGBoost** is a gradient boosting algorithm.\n",
        "\n",
        "- Let's initialize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy1-kKRIE2Nz"
      },
      "source": [
        "- We initialize the DMatrix objects for training and validation, starting from the datasets. We also set some of the parameters used for the model tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yesqvArE4uu"
      },
      "source": [
        "# Prepare the train and valid datasets\n",
        "dtrain = xgb.DMatrix(train_df[predictors], train_df[target].values)\n",
        "dvalid = xgb.DMatrix(valid_df[predictors], valid_df[target].values)\n",
        "dtest = xgb.DMatrix(test_df[predictors], test_df[target].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CCIuvcqFBxI"
      },
      "source": [
        "#What to monitor (in this case, **train** and **valid**)\n",
        "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWgmpyyjFE-o"
      },
      "source": [
        "# Set xgboost parameters\n",
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eta'] = 0.039\n",
        "params['silent'] = True\n",
        "params['max_depth'] = 2\n",
        "params['subsample'] = 0.8\n",
        "params['colsample_bytree'] = 0.9\n",
        "params['eval_metric'] = 'auc'\n",
        "params['random_state'] = RANDOM_STATE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP4g3InmFOs1"
      },
      "source": [
        "#### **Train the model**\n",
        "\n",
        "- Now, let's train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vQnyP1FT7j"
      },
      "source": [
        "model = xgb.train(params,\n",
        "                dtrain,\n",
        "                MAX_ROUNDS,\n",
        "                watchlist,\n",
        "                early_stopping_rounds=EARLY_STOP,\n",
        "                maximize=True,\n",
        "                verbose_eval=VERBOSE_EVAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLXzCByTGQjq"
      },
      "source": [
        "- The best validation score (ROC-AUC) was 0.986, for round 258."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yysPpetDGok7"
      },
      "source": [
        "#### **Plot variable importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COgvZGw6GrxB"
      },
      "source": [
        "fig, (ax) = plt.subplots(ncols=1, figsize=(12,8))\n",
        "xgb.plot_importance(model, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPgXf8MFHG2s"
      },
      "source": [
        "#### **Predict test set**\n",
        "\n",
        "- We used the train and validation sets for training and validation. We will use the trained model now to predict the target value for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFak9QGLHMcT"
      },
      "source": [
        "preds = model.predict(dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fA-jp7HTpK"
      },
      "source": [
        "#### **ROC-AUC Score**\n",
        "\n",
        "- Now, let's calculate the ROC-AUC Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMXmjNr8HeJr"
      },
      "source": [
        "roc_auc_score(test_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmUaUz26HntF"
      },
      "source": [
        "- The ROC- AUC score for the prediction of fresh data (test set) is 0.977."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p849l0-yKMCP"
      },
      "source": [
        "### **LightGBM Classifier**\n",
        "\n",
        "- Now, we will  predict with another gradient boosting algorithm - LightGBM Classifier model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q4Y4s7qK_Lx"
      },
      "source": [
        "#### **Define model parameters**\n",
        "\n",
        "- Now, let's set the parameters for the model. We will use these parameters for the lgb model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlpOkAywLVXE"
      },
      "source": [
        "params = {\n",
        "          'boosting_type': 'gbdt',\n",
        "          'objective': 'binary',\n",
        "          'metric':'auc',\n",
        "          'learning_rate': 0.05,\n",
        "          'num_leaves': 7,  # we should let it be smaller than 2^(max_depth)\n",
        "          'max_depth': 4,  # -1 means no limit\n",
        "          'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
        "          'max_bin': 100,  # Number of bucketed bin for feature values\n",
        "          'subsample': 0.9,  # Subsample ratio of the training instance.\n",
        "          'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
        "          'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n",
        "          'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
        "          'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
        "          'nthread': 8,\n",
        "          'verbose': 0,\n",
        "          'scale_pos_weight':150, # because training data is extremely unbalanced\n",
        "         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KpVXaXyMBU2"
      },
      "source": [
        "#### **Initialize the model**\n",
        "\n",
        "- Now, let's initialize the model, creating the Datasets data structures from the train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l--Sg179MKqz"
      },
      "source": [
        "dtrain = lgb.Dataset(train_df[predictors].values,\n",
        "                     label=train_df[target].values,\n",
        "                     feature_name=predictors)\n",
        "\n",
        "dvalid = lgb.Dataset(valid_df[predictors].values,\n",
        "                     label=valid_df[target].values,\n",
        "                     feature_name=predictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq9qpXdAMdKj"
      },
      "source": [
        "#### **Run the model**\n",
        "\n",
        "- Now, let's run the model, using the **train** function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJQYX5vL2zs"
      },
      "source": [
        "evals_results = {}\n",
        "\n",
        "model = lgb.train(params,\n",
        "                  dtrain,\n",
        "                  valid_sets=[dtrain, dvalid],\n",
        "                  valid_names=['train','valid'],\n",
        "                  evals_result=evals_results,\n",
        "                  num_boost_round=MAX_ROUNDS,\n",
        "                  early_stopping_rounds=2*EARLY_STOP,\n",
        "                  verbose_eval=VERBOSE_EVAL,\n",
        "                  feval=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9J2YT2VRqlR"
      },
      "source": [
        "- We can see that the best validation score was obtained for round 85, for which AUC ~= 0.974."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcfgtcwSF9j"
      },
      "source": [
        "#### **Plot variable importance**\n",
        "\n",
        "- Now, let's plot variable importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWscH9vRSNGe"
      },
      "source": [
        "fig, (ax) = plt.subplots(ncols=1, figsize=(10,8))\n",
        "lgb.plot_importance(model, height=0.8, title=\"Features importance (LightGBM)\", ax=ax, color=\"green\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynBlpbnqSka3"
      },
      "source": [
        "#### **Predict test data**\n",
        "\n",
        "\n",
        "- Now, let's predict the target for the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzR_ut2qSs_K"
      },
      "source": [
        "preds = model.predict(test_df[predictors])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjd7c7WQTJYa"
      },
      "source": [
        "#### **ROC-AUC Score**\n",
        "\n",
        "- Now, let's calculate the ROC-AUC score for the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0q380DdTTpx"
      },
      "source": [
        "roc_auc_score(test_df[target].values, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Ui7oFRTaoF"
      },
      "source": [
        "- The ROC-AUC score obtained for the test set is 0.946."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3nwf5bnThFE"
      },
      "source": [
        "#### **Training and validation using cross-validation**\n",
        "\n",
        "- We will now use now cross-validation. We will use cross-validation (KFolds) with 5 folds. Data is divided in 5 folds and, by rotation, we are training using 4 folds (n-1) and validate using the 5th (nth) fold.\n",
        "\n",
        "- Test set is calculated as an average of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJkAR0dyTrRX"
      },
      "source": [
        "kf = KFold(n_splits = NUMBER_KFOLDS, random_state = RANDOM_STATE, shuffle = True)\n",
        "\n",
        "# Create arrays and dataframes to store results\n",
        "oof_preds = np.zeros(train_df.shape[0])\n",
        "test_preds = np.zeros(test_df.shape[0])\n",
        "feature_importance_df = pd.DataFrame()\n",
        "n_fold = 0\n",
        "for train_idx, valid_idx in kf.split(train_df):\n",
        "    train_x, train_y = train_df[predictors].iloc[train_idx],train_df[target].iloc[train_idx]\n",
        "    valid_x, valid_y = train_df[predictors].iloc[valid_idx],train_df[target].iloc[valid_idx]\n",
        "\n",
        "    evals_results = {}\n",
        "    model =  LGBMClassifier(\n",
        "                  nthread=-1,\n",
        "                  n_estimators=2000,\n",
        "                  learning_rate=0.01,\n",
        "                  num_leaves=80,\n",
        "                  colsample_bytree=0.98,\n",
        "                  subsample=0.78,\n",
        "                  reg_alpha=0.04,\n",
        "                  reg_lambda=0.073,\n",
        "                  subsample_for_bin=50,\n",
        "                  boosting_type='gbdt',\n",
        "                  is_unbalance=False,\n",
        "                  min_split_gain=0.025,\n",
        "                  min_child_weight=40,\n",
        "                  min_child_samples=510,\n",
        "                  objective='binary',\n",
        "                  metric='auc',\n",
        "                  silent=-1,\n",
        "                  verbose=-1,\n",
        "                  feval=None)\n",
        "    model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
        "                eval_metric= 'auc', verbose= VERBOSE_EVAL, early_stopping_rounds= EARLY_STOP)\n",
        "\n",
        "    oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n",
        "    test_preds += model.predict_proba(test_df[predictors], num_iteration=model.best_iteration_)[:, 1] / kf.n_splits\n",
        "\n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"feature\"] = predictors\n",
        "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
        "    fold_importance_df[\"fold\"] = n_fold + 1\n",
        "\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
        "    del model, train_x, train_y, valid_x, valid_y\n",
        "    gc.collect()\n",
        "    n_fold = n_fold + 1\n",
        "train_auc_score = roc_auc_score(train_df[target], oof_preds)\n",
        "print('Full AUC score %.6f' % train_auc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pJS9cuEUBKD"
      },
      "source": [
        "- The AUC score for the prediction from the test data was 0.931823.\n",
        "\n",
        "- We prepare the test prediction, from the averaged predictions for test over the 5 folds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvsN2-IJUoJg"
      },
      "source": [
        "## **6. Results and conclusion**\n",
        "\n",
        "\n",
        "- We investigated the data, checking for data unbalancing, visualizing the features and understanding the relationship between different features. We then investigated two predictive models. The data was split in 3 parts, a train set, a validation set and a test set. For the first three models, we only used the train and test set.\n",
        "\n",
        "- We started with RandomForrestClassifier, for which we obtained an AUC score of 0.85 when predicting the target for the test set.\n",
        "\n",
        "- We followed with an AdaBoostClassifier model, with lower AUC score (0.83) for prediction of the test set target values.\n",
        "\n",
        "- We then followed with an CatBoostClassifier, with the AUC score after training 500 iterations 0.86.\n",
        "\n",
        "- We then experimented with a XGBoost model. In this case, se used the validation set for validation of the training model. The best validation score obtained was 0.986. Then we used the model with the best training step, to predict target value from the test data; the AUC score obtained was 0.977.\n",
        "\n",
        "- We then presented the data to a LightGBM model. We used both train-validation split and cross-validation to evaluate the model effectiveness to predict 'Class' value, i.e. detecting if a transaction was fraudulent. With the first method we obtained values of AUC for the validation set around 0.974. For the test set, the score obtained was 0.946.\n",
        "With the cross-validation, we obtained an AUC score for the test prediction of 0.93.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHhcMagVwrm"
      },
      "source": [
        "## **7. References**\n",
        "\n",
        "\n",
        "The concepts and ideas in this project are taken from the following websites -\n",
        "\n",
        "1. [Credit-Card Fraud Detection Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
        "2. [Random Forest Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "3. [AdaBoost Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
        "4. [CatBoost Classifier Documentation](https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html)\n",
        "5. [XGBoost Python API Reference](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
        "6. [LightGBM Python Implemwentation](https://github.com/Microsoft/LightGBM/tree/master/python-package)"
      ]
    }
  ]
}